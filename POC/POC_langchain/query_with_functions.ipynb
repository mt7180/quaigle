{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI queries with tools (functions)\n",
    "### - provide OpenAI API with different functions to call in addition to its own knowledge base\n",
    "- Wolfram Alpha API: provide OpenAI access to real-time data, mathematical and scientific knowledge\n",
    "- Talk to your own database with the help of chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
    "from langchain import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# load your API key to the environment variables\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wolframalpha\n",
    "import ssl\n",
    "import requests\n",
    "import certifi\n",
    "\n",
    "# workaround for mac to solve SSL: CERTIFICATE_VERIFY_FAILED Error\n",
    "os.environ[\"REQUESTS_CA_BUNDLE\"] = certifi.where()\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# provide OpenAI access to real-time data, mathematical and scientific knowledge\n",
    "# llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "wolfram = WolframAlphaAPIWrapper()\n",
    "\n",
    "# provide OpenAI access to data in specific database (in this case: kaggle Amazon \n",
    "# database about customers' reviews and their helpfulness)\n",
    "db = SQLDatabase.from_uri(\"sqlite:///data/database.sqlite\")\n",
    "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True, use_query_checker=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        #func=llm_math_chain.run,\n",
    "        func=wolfram.run,\n",
    "        description=\"useful for when you need to answer questions about real time data, mathematical computations or science problems\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"kaggle_amazon_db\",\n",
    "        func=db_chain.run,\n",
    "        description=\"useful for when you need to answer questions about amazon customers' \\\n",
    "            reviews and their helpfulness. Input should be in the form of a question containing full context\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = agent.run(\"What is the name of the user who wrote the largest number of helpful reviews for amazon?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    answer = agent.run(\"What is 2x+5 = -3x + 7?\")\n",
    "except Exception as e:\n",
    "    with open('error_out.txt', 'w') as out_file:\n",
    "        out_file.write(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = agent.run(\"How far is it from Chicago to Tokyo?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = agent.run(\"Make a picture of an airy function using the Calculator tool.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use the wolframalpha library directly to get access to detailed parameters\n",
    "\n",
    "- the langchain WolframAlphaAPIWrapper does not give access to request parameters or detailed response of the api\n",
    "- by tuning the request parameters it is  possible to get images from the wolfram alpha API like wit the chatgpt plus wolfram alpha plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = wolframalpha.Client(os.getenv('WOLFRAM_ALPHA_APPID'))\n",
    "  \n",
    "res = client.query('How far is it from Chicago to Tokyo?')\n",
    "  \n",
    "answer = next(res.results)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make direct request without any wolfram alpha library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = \"sin x cos y\"\n",
    "wa_appid = os.getenv('WOLFRAM_ALPHA_APPID')\n",
    "query = f\"plot {function}\"\n",
    "query_url = f\"http://api.wolframalpha.com/v2/query?\" \\\n",
    "            f\"appid={wa_appid}\" \\\n",
    "            f\"&input={query}\" \\\n",
    "            f\"&output=json\" \\\n",
    "            f\"&includepodid=3DPlot\" \\\n",
    "            f\"&includepodid=ContourPlot\"\n",
    "\n",
    "r = requests.get(query_url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import Image, display\n",
    "\n",
    "image_url = r[\"queryresult\"][\"pods\"][0][\"subpods\"][0][\"img\"][\"src\"]\n",
    "#r2 = requests.get(image_url)\n",
    "\n",
    "Image(url=image_url,format='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = \"How far is the distance between Chicago and Tokyo?\"\n",
    "wa_appid = os.getenv('WOLFRAM_ALPHA_APPID')\n",
    "query = f\"plot {function}\"\n",
    "query_url = f\"http://api.wolframalpha.com/v2/query?\" \\\n",
    "            f\"appid={wa_appid}\" \\\n",
    "            f\"&input={query}\" \\\n",
    "            f\"&output=json\" \\\n",
    "            f\"&includepodid=3DPlot\" \\\n",
    "            f\"&includepodid=ContourPlot\"\n",
    "\n",
    "r = requests.get(query_url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #image_url2 = r[\"queryresult\"][\"pods\"][0][\"subpods\"][0][\"img\"][\"src\"]\n",
    "    pods = r[\"queryresult\"].get('pods', None)\n",
    "    if pods:\n",
    "        image_url2 = pods[0][\"subpods\"][0][\"img\"][\"src\"]\n",
    "        Image(url=image_url2,format='gif')\n",
    "except Exception as e:\n",
    "    print(f\"wolfram alpha result json structure does not match common structure: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "- https://python.langchain.com/docs/modules/agents/agent_types/openai_functions_agent\n",
    "- https://python.langchain.com/docs/integrations/tools/wolfram_alpha\n",
    "- https://api.python.langchain.com/en/latest/utilities/langchain.utilities.wolfram_alpha.WolframAlphaAPIWrapper.html\n",
    "- https://api.python.langchain.com/en/latest/_modules/langchain/tools/wolfram_alpha/tool.html\n",
    "- https://towardsdatascience.com/build-your-next-project-with-wolfram-alpha-api-and-python-51c2c361d8b9\n",
    "- https://www.packtpub.com/article-hub/unleashing-the-power-of-wolfram-alpha-api-with-python-and-chatgpt\n",
    "- https://blog.finxter.com/openai-api-functions-embeddings-course-4-7-database-querying-using-chatgpt/\n",
    "- https://medium.com/mlearning-ai/chatting-with-your-database-using-langchain-e27893eb840a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
