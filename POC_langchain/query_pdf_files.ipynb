{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate local data into openai knowledge base via vector-db\n",
    "## Part II: pdf-files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector databases are a powerful and emerging class of databases engineered to manage and process structured data in a highly efficient way. They achieve this by indexing and storing vector embeddings, allowing for fast data retrieval. In this context, each data point is depicted as a numerical vector (embedding), making it well-suited for mathematical operations and analysis through machine learning algorithms.\n",
    "\n",
    "These databases empower vector-based search, also known as semantic search, not by relying on exact keyword matching, but by considering the actual meaning of the query. Through the encoding of datasets into meaningful vector representations, the distance between vectors reflects the similarities between the elements. Utilizing algorithms like Approximate Nearest Neighbor (ANN), they enable rapid retrieval of results that closely match the query, facilitating efficient and precise searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vector database](https://miro.medium.com/v2/resize:fit:640/format:webp/0*d8Utelp6ffNhi_eY.png)\n",
    "\n",
    "Source: https://odsc.medium.com/a-gentle-introduction-to-vector-search-3c0511bc6771"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import librarys and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Reference:\n",
    "- [openai](https://platform.openai.com/docs/api-reference?lang=python)\n",
    "- [langchain document_loaders](https://python.langchain.com/docs/modules/data_connection/document_loaders/)\n",
    "- [langchain agents](https://python.langchain.com/docs/modules/agents/)\n",
    "- [FAISS vector database](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.faiss.FAISS.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load documents, make embeddings and put them into a vector database\n",
    "- load documents into memory with <span style=\"color:#40E0D0\">langchain.document_loaders</span>\n",
    "- chunk documents into text pieces of given length and with given overlap to garantee for meaningful context with <span style=\"color:#40E0D0\">langchain.text_splitter.RecursiveCharacterTextSplitter</span>\n",
    "- create word embeddings in the form of embedding vectors for the given text with <span style=\"color:#40E0D0\">langchain.embeddings.OpenaiEmbeddings</span>\n",
    "- load the vectors into a vector database (FAISS) with <span style=\"color:#40E0D0\">langchain.vectorstores</span>\n",
    "- pickle the db for re-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_loader = DirectoryLoader('./data', glob=\"**/*.pdf\", loader_cls=PyPDFLoader, show_progress=True)\n",
    "docs = document_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "splitted_docs = text_splitter.split_documents(docs)\n",
    "print(len(splitted_docs),splitted_docs[0]) # show first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(splitted_docs, embeddings)\n",
    "\n",
    "with open('vectorstore_pdf.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorstore, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Query including vector database and query-history\n",
    "- load pickeled vectorstore database\n",
    "- define the Large Language Model (LLM) parameters\n",
    "- define Question Answer template\n",
    "- set up the memory for chat history\n",
    "- Make queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('vectorstore_pdf.pkl', 'rb') as pickled_file:\n",
    "    vectorstore = pickle.load(pickled_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    openai_api_key=API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_template = \"\"\"The following is a conversation with an AI research assistant. \n",
    "The assistant tone is technical and scientific. \n",
    "I will provide you pieces of [Context] to answer the [Question].\n",
    "If you don't know the answer based on [Context] just say that you don't know, don't try to make up an answer. \\\n",
    "[Context]: {context} \\\n",
    "[Question]: {question} \\\n",
    "AI Answer:\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, output_key='answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(input_variables=[ \"question\", \"context\"], template=prompt_template)\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    memory=chat_history,\n",
    "    retriever=vectorstore.as_retriever(search_type=\"similarity\"),\n",
    "    # max_tokens_limit=4000,\n",
    "    combine_docs_chain_kwargs={'prompt': PROMPT }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa({'question': 'What are the key findings concerning the ensemble method for estimating the number of clusters?'})\n",
    "print(result.get(\"answer\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa({'question': 'Please describe in short paragraphs what is done in each step of the new ensemble model.'})[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa({'question': 'Please describe in short paragraphs what is done in each step of the new ensemble model to estimate the optimal number of clusters.'})[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://github.com/Coding-Crashkurse/LangChain-Basics/blob/main/basics.ipynb\n",
    "- https://python.langchain.com/docs/integrations/toolkits/document_comparison_toolkit\n",
    "- https://artificialcorner.com/use-langchain-and-gpt-3-5-to-chat-with-your-favorite-podcast-guests-b97d1ddd42e1\n",
    "- https://towardsdatascience.com/4-ways-of-question-answering-in-langchain-188c6707cc5a\n",
    "- https://www.linkedin.com/pulse/how-use-streamlit-app-build-chatbot-can-respond-questions-shah\n",
    "- https://amaarora.github.io/posts/2023-07-27_Document_Question_Answering_with_LangChain.html\n",
    "- https://medium.com/mlearning-ai/build-a-chat-with-csv-app-using-langchain-and-streamlit-94a8b3363aa9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
